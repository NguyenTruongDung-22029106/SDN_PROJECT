#!/usr/bin/env python3
"""
So s√°nh Training Data vs Runtime Data ƒë·ªÉ t√¨m nguy√™n nh√¢n False Positives
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

def _get_output_dir():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(base_dir, "output")
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

def main():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    # Load training data
    train_path = os.path.abspath(os.path.join(base_dir, "..", "dataset", "result.csv"))
    runtime_path = os.path.abspath(os.path.join(base_dir, "..", "data", "result.csv"))
    
    print("=" * 70)
    print("SO S√ÅNH TRAINING DATA vs RUNTIME DATA")
    print("=" * 70)
    
    # Load data
    train_df = pd.read_csv(train_path, on_bad_lines='skip')
    runtime_df = pd.read_csv(runtime_path, on_bad_lines='skip')
    
    # Ch·ªâ l·∫•y ML predictions t·ª´ runtime
    runtime_ml = runtime_df[runtime_df['reason'] == 'ml'].copy() if 'reason' in runtime_df.columns else runtime_df.copy()
    
    print(f"\nüìä Training Data (dataset/result.csv):")
    print(f"   T·ªïng: {len(train_df)} samples")
    print(f"   Normal: {(train_df['label'] == 0).sum()} ({(train_df['label'] == 0).sum()/len(train_df)*100:.1f}%)")
    print(f"   Attack: {(train_df['label'] == 1).sum()} ({(train_df['label'] == 1).sum()/len(train_df)*100:.1f}%)")
    
    print(f"\nüìä Runtime Data - ML Predictions (data/result.csv, reason='ml'):")
    print(f"   T·ªïng: {len(runtime_ml)} samples")
    print(f"   Normal: {(runtime_ml['label'] == 0).sum()} ({(runtime_ml['label'] == 0).sum()/len(runtime_ml)*100:.1f}%)")
    print(f"   Attack: {(runtime_ml['label'] == 1).sum()} ({(runtime_ml['label'] == 1).sum()/len(runtime_ml)*100:.1f}%)")
    
    # So s√°nh feature distributions
    print(f"\nüìà So s√°nh Feature Distributions:")
    
    features = ['sfe', 'ssip', 'rfip']
    for feat in features:
        train_normal = train_df[train_df['label'] == 0][feat].abs() if feat in ['sfe', 'ssip'] else train_df[train_df['label'] == 0][feat]
        train_attack = train_df[train_df['label'] == 1][feat].abs() if feat in ['sfe', 'ssip'] else train_df[train_df['label'] == 1][feat]
        runtime_normal = runtime_ml[runtime_ml['label'] == 0][feat].abs() if feat in ['sfe', 'ssip'] else runtime_ml[runtime_ml['label'] == 0][feat]
        runtime_attack = runtime_ml[runtime_ml['label'] == 1][feat].abs() if feat in ['sfe', 'ssip'] else runtime_ml[runtime_ml['label'] == 1][feat]
        
        print(f"\n   {feat.upper()}:")
        print(f"     Training - Normal:  min={train_normal.min():.1f}, max={train_normal.max():.1f}, mean={train_normal.mean():.1f}")
        print(f"     Training - Attack:  min={train_attack.min():.1f}, max={train_attack.max():.1f}, mean={train_attack.mean():.1f}")
        print(f"     Runtime - Normal:   min={runtime_normal.min():.1f}, max={runtime_normal.max():.1f}, mean={runtime_normal.mean():.1f}")
        print(f"     Runtime - Attack:   min={runtime_attack.min():.1f}, max={runtime_attack.max():.1f}, mean={runtime_attack.mean():.1f}")
        
        # Ki·ªÉm tra overlap
        if runtime_normal.max() > train_normal.max() * 1.5:
            print(f"     ‚ö†Ô∏è  Runtime Normal c√≥ gi√° tr·ªã cao h∆°n Training Normal nhi·ªÅu!")
        if runtime_normal.mean() > train_normal.mean() * 2:
            print(f"     ‚ö†Ô∏è  Runtime Normal c√≥ mean cao h∆°n Training Normal g·∫•p 2 l·∫ßn!")
    
    # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
    output_dir = _get_output_dir()
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    for idx, feat in enumerate(features):
        ax = axes[idx]
        
        # Training data
        train_normal = train_df[train_df['label'] == 0][feat].abs() if feat in ['sfe', 'ssip'] else train_df[train_df['label'] == 0][feat]
        train_attack = train_df[train_df['label'] == 1][feat].abs() if feat in ['sfe', 'ssip'] else train_df[train_df['label'] == 1][feat]
        
        # Runtime data
        runtime_normal = runtime_ml[runtime_ml['label'] == 0][feat].abs() if feat in ['sfe', 'ssip'] else runtime_ml[runtime_ml['label'] == 0][feat]
        runtime_attack = runtime_ml[runtime_ml['label'] == 1][feat].abs() if feat in ['sfe', 'ssip'] else runtime_ml[runtime_ml['label'] == 1][feat]
        
        # Histogram
        max_val = max(
            train_df[feat].abs().max() if feat in ['sfe', 'ssip'] else train_df[feat].max(),
            runtime_ml[feat].abs().max() if feat in ['sfe', 'ssip'] else runtime_ml[feat].max()
        )
        bins = np.linspace(0, max_val, 50)
        
        ax.hist(train_normal, bins=bins, alpha=0.5, label='Train Normal', color='blue', density=True)
        ax.hist(train_attack, bins=bins, alpha=0.5, label='Train Attack', color='red', density=True)
        ax.hist(runtime_normal, bins=bins, alpha=0.3, label='Runtime Normal', color='cyan', density=True, histtype='step', linewidth=2)
        ax.hist(runtime_attack, bins=bins, alpha=0.3, label='Runtime Attack', color='orange', density=True, histtype='step', linewidth=2)
        
        ax.set_xlabel(feat.upper())
        ax.set_ylabel('Density')
        ax.set_title(f'{feat.upper()} Distribution Comparison')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    out_path = os.path.join(output_dir, 'training_vs_runtime_comparison.png')
    plt.savefig(out_path, dpi=200)
    plt.close()
    print(f"\n‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {out_path}")
    
    # Ph√¢n t√≠ch v·∫•n ƒë·ªÅ
    print(f"\n{'='*70}")
    print("PH√ÇN T√çCH V·∫§N ƒê·ªÄ")
    print(f"{'='*70}")
    
    # Ki·ªÉm tra n·∫øu runtime normal c√≥ features gi·ªëng attack
    train_normal_sfe = train_df[train_df['label'] == 0]['sfe'].abs()
    train_attack_sfe = train_df[train_df['label'] == 1]['sfe'].abs()
    runtime_normal_sfe = runtime_ml[runtime_ml['label'] == 0]['sfe'].abs()
    
    runtime_normal_high_sfe = runtime_normal_sfe[runtime_normal_sfe > train_attack_sfe.mean()]
    if len(runtime_normal_high_sfe) > 0:
        print(f"\n‚ö†Ô∏è  V·∫§N ƒê·ªÄ PH√ÅT HI·ªÜN:")
        print(f"   {len(runtime_normal_high_sfe)} Normal samples trong runtime c√≥ SFE > mean c·ªßa Attack trong training")
        print(f"   Chi·∫øm: {len(runtime_normal_high_sfe)/len(runtime_normal_sfe)*100:.1f}% t·ªïng Normal samples")
        print(f"   ‚Üí Model c√≥ th·ªÉ ph√¢n lo·∫°i nh·ªØng samples n√†y th√†nh Attack (False Positive)")
        print(f"\nüí° GI·∫¢I PH√ÅP:")
        print(f"   1. Thu th·∫≠p th√™m Normal data v·ªõi SFE/SSIP cao h∆°n ƒë·ªÉ train model")
        print(f"   2. ƒêi·ªÅu ch·ªânh confidence threshold cao h∆°n")
        print(f"   3. S·ª≠ d·ª•ng model c√≥ FAR th·∫•p h∆°n (Decision Tree ho·∫∑c Random Forest)")

if __name__ == "__main__":
    main()

